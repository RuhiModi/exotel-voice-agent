/*************************************************
 * GUJARATI AI VOICE AGENT â€” HYBRID STABLE
 * Logs on END + Logs on disconnect
 *************************************************/

import express from "express";
import bodyParser from "body-parser";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import textToSpeech from "@google-cloud/text-to-speech";
import { google } from "googleapis";

dotenv.config();

const app = express();
app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());

const PORT = process.env.PORT || 10000;
const BASE_URL = process.env.BASE_URL;

/* ================= FILE SETUP ================= */
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/* ================= AUDIO ================= */
const AUDIO_DIR = path.join(__dirname, "audio");
if (!fs.existsSync(AUDIO_DIR)) fs.mkdirSync(AUDIO_DIR);
app.use("/audio", express.static(AUDIO_DIR));

const ttsClient = new textToSpeech.TextToSpeechClient();

/* ================= GOOGLE SHEETS ================= */
const auth = new google.auth.GoogleAuth({
  scopes: ["https://www.googleapis.com/auth/spreadsheets"]
});
const sheets = google.sheets({ version: "v4", auth });
const SHEET_ID = process.env.GOOGLE_SHEET_ID;
const SHEET_RANGE = "Sheet1!A:H"; // ðŸ”´ keep SAME tab name you used before

async function logToSheet(call) {
  if (call.logged) return; // ðŸ›‘ prevent duplicates
  call.logged = true;

  await sheets.spreadsheets.values.append({
    spreadsheetId: SHEET_ID,
    range: SHEET_RANGE,
    valueInputOption: "USER_ENTERED",
    requestBody: {
      values: [[
        new Date().toISOString(),
        call.sid,
        call.from || "",
        "gu-IN",
        call.agentText || "",
        call.userText || "",
        call.status || "completed",
        call.duration || ""
      ]]
    }
  });
}

/* ================= MEMORY ================= */
const calls = new Map();

/* ================= FLOW ================= */
const FLOW = {
  intro: {
    prompt:
      "àª¨àª®àª¸à«àª¤à«‡, àª¹à«àª‚ àª¦àª°àª¿àª¯àª¾àªªà«àª°àª¨àª¾ àª§àª¾àª°àª¾àª¸àª­à«àª¯ àª•à«Œàª¶àª¿àª• àªœà«ˆàª¨àª¨àª¾ àª‡-àª•àª¾àª°à«àª¯àª¾àª²àª¯ àª¤àª°àª«àª¥à«€ àª¬à«‹àª²à«àª‚ àª›à«àª‚. àª¶à«àª‚ àª¹à«àª‚ àª†àªªàª¨à«‹ àª¥à«‹àª¡à«‹ àª¸àª®àª¯ àª²àªˆ àª¶àª•à«àª‚?",
    next: (t) => {
      if (/àª¹àª¾|àªšàª¾àª²à«‡/.test(t)) return "task_check";
      return null;
    }
  },
  task_check: {
    prompt: "àª¯à«‹àªœàª¨àª¾àª•à«€àª¯ àª•à«‡àª®à«àªª àª¦àª°àª®à«àª¯àª¾àª¨ àª†àªªàª¨à«àª‚ àª•àª¾àª® àªªà«‚àª°à«àª£ àª¥àª¯à«àª‚ àª›à«‡ àª•à«‡ àª¨àª¹à«€àª‚?",
    next: (t) => {
      if (/àªªà«‚àª°à«àª£/.test(t)) return "done";
      if (/àª¨àª¥à«€|àª¬àª¾àª•à«€/.test(t)) return "pending";
      return null;
    }
  },
  done: {
    prompt: "àª†àª­àª¾àª°. àª†àªªàª¨à«‹ àªªà«àª°àª¤àª¿àª¸àª¾àª¦ àª¨à«‹àª‚àª§àª¾àª¯à«‹ àª›à«‡.",
    end: true
  },
  pending: {
    prompt: "àª†àª­àª¾àª°. àª†àªªàª¨à«€ àª«àª°àª¿àª¯àª¾àª¦ àª¨à«‹àª‚àª§àª¾àªˆ àª—àªˆ àª›à«‡.",
    end: true
  }
};

/* ================= TTS ================= */
async function speak(text, file) {
  const filePath = path.join(AUDIO_DIR, file);
  if (!fs.existsSync(filePath)) {
    const [res] = await ttsClient.synthesizeSpeech({
      input: { text },
      voice: { languageCode: "gu-IN" },
      audioConfig: { audioEncoding: "MP3" }
    });
    fs.writeFileSync(filePath, res.audioContent);
  }
  return `${BASE_URL}/audio/${file}`;
}

/* ================= ANSWER ================= */
app.post("/answer", async (req, res) => {
  const sid = req.body.CallSid;

  calls.set(sid, {
    sid,
    from: req.body.From,
    state: "intro",
    agentText: FLOW.intro.prompt,
    userText: "",
    status: "in-progress",
    startTime: Date.now(),
    logged: false
  });

  const audio = await speak(FLOW.intro.prompt, "intro.mp3");

  res.type("text/xml").send(`
<Response>
  <Play>${audio}</Play>
  <Gather input="speech"
          language="gu-IN"
          action="${BASE_URL}/listen"
          timeout="6"
          speechTimeout="auto"/>
</Response>
`);
});

/* ================= LISTEN ================= */
app.post("/listen", async (req, res) => {
  const sid = req.body.CallSid;
  const call = calls.get(sid);

  if (!call) {
    return res.type("text/xml").send("<Response><Hangup/></Response>");
  }

  const text = (req.body.SpeechResult || "").trim();
  if (text) call.userText += ` ${text}`;

  const state = FLOW[call.state];
  const nextId = state.next(text);
  const next = FLOW[nextId];

  if (!next) {
    const retry = await speak("àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª«àª°à«€ àª•àª¹à«‡àª¶à«‹?", "retry.mp3");
    return res.type("text/xml").send(`
<Response>
  <Play>${retry}</Play>
  <Gather input="speech"
          language="gu-IN"
          action="${BASE_URL}/listen"
          timeout="6"
          speechTimeout="auto"/>
</Response>
`);
  }

  call.agentText += ` | ${next.prompt}`;
  const audio = await speak(next.prompt, `${nextId}.mp3`);

  if (next.end) {
    call.status = "completed";
    call.duration = Math.floor((Date.now() - call.startTime) / 1000);
    await logToSheet(call); // âœ… END logging
    calls.delete(sid);

    return res.type("text/xml").send(`
<Response>
  <Play>${audio}</Play>
  <Hangup/>
</Response>
`);
  }

  call.state = nextId;
  res.type("text/xml").send(`
<Response>
  <Play>${audio}</Play>
  <Gather input="speech"
          language="gu-IN"
          action="${BASE_URL}/listen"
          timeout="6"
          speechTimeout="auto"/>
</Response>
`);
});

/* ================= DISCONNECT FALLBACK ================= */
app.post("/call-status", async (req, res) => {
  const sid = req.body.CallSid;
  const call = calls.get(sid);

  if (call && !call.logged) {
    call.status = req.body.CallStatus || "disconnected";
    call.duration = Math.floor((Date.now() - call.startTime) / 1000);
    await logToSheet(call); // âœ… disconnect logging
    calls.delete(sid);
  }

  res.sendStatus(200);
});

/* ================= START ================= */
app.listen(PORT, () => {
  console.log("âœ… Gujarati AI Voice Agent running (HYBRID STABLE)");
});
