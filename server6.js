/*************************************************
 * GUJARATI AI VOICE AGENT â€“ FINAL PRODUCTION FILE
 * Outbound + Inbound | Twilio + Groq + Google TTS
 *************************************************/

import express from "express";
import bodyParser from "body-parser";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import fetch from "node-fetch";
import twilio from "twilio";
import textToSpeech from "@google-cloud/text-to-speech";
import { google } from "googleapis";

dotenv.config();

/* ======================
   APP SETUP
====================== */
const app = express();
app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());

const PORT = process.env.PORT || 10000;
const BASE_URL = process.env.BASE_URL;

/* ======================
   TWILIO CLIENT
====================== */
const twilioClient = twilio(
  process.env.TWILIO_ACCOUNT_SID,
  process.env.TWILIO_AUTH_TOKEN
);

/* ======================
   GOOGLE TTS
====================== */
const ttsClient = new textToSpeech.TextToSpeechClient();

/* ======================
   GOOGLE SHEETS
====================== */
const auth = new google.auth.GoogleAuth({
  credentials: JSON.parse(process.env.GOOGLE_SERVICE_ACCOUNT),
  scopes: ["https://www.googleapis.com/auth/spreadsheets"]
});
const sheets = google.sheets({ version: "v4", auth });
const SHEET_ID = process.env.GOOGLE_SHEET_ID;

/* ======================
   FILE SYSTEM
====================== */
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const AUDIO_DIR = path.join(__dirname, "audio");

if (!fs.existsSync(AUDIO_DIR)) fs.mkdirSync(AUDIO_DIR);
app.use("/audio", express.static(AUDIO_DIR));

/* ======================
   CALL SESSION MEMORY
====================== */
const callSessions = new Map();

/* ======================
   FIXED SCRIPT FLOW
====================== */
const FLOW = {
  intro: {
    prompt:
      "àª¨àª®àª¸à«àª¤à«‡, àª¹à«àª‚ àª¦àª°àª¿àª¯àª¾àªªà«àª°àª¨àª¾ àª§àª¾àª°àª¾àª¸àª­à«àª¯ àª•à«Œàª¶àª¿àª• àªœà«ˆàª¨àª¨àª¾ àª‡-àª•àª¾àª°à«àª¯àª¾àª²àª¯ àª¤àª°àª«àª¥à«€ àª¬à«‹àª²à«àª‚ àª›à«àª‚. àª¯à«‹àªœàª¨àª¾àª•à«€àª¯ àª•à«‡àª®à«àªª àª¦àª°àª®àª¿àª¯àª¾àª¨ àª†àªªàª¨à«àª‚ àª•àª¾àª® àª¥àª¯à«‡àª² àª›à«‡ àª•à«‡ àª¨àª¹à«€àª‚ àª¤à«‡àª¨à«€ àªªà«àª·à«àªŸàª¿ àª®àª¾àªŸà«‡ àª† àª•à«‰àª² àª›à«‡. àª¶à«àª‚ àª¹à«àª‚ àª†àªªàª¨à«‹ àª¥à«‹àª¡à«‹ àª¸àª®àª¯ àª²àªˆ àª¶àª•à«àª‚?"
  },

  task_check: {
    prompt:
      "àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àªœàª£àª¾àªµàª¶à«‹ àª•à«‡ àª¯à«‹àªœàª¨àª¾àª•à«€àª¯ àª•à«‡àª®à«àªª àª¦àª°àª®àª¿àª¯àª¾àª¨ àª†àªªàª¨à«àª‚ àª•àª¾àª® àªªà«‚àª°à«àª£ àª¥àª¯à«àª‚ àª›à«‡ àª•à«‡ àª¨àª¹à«€àª‚?"
  },

  task_done: {
    prompt:
      "àª–à«‚àª¬ àª†àª¨àª‚àª¦ àª¥àª¯à«‹ àª•à«‡ àª†àªªàª¨à«àª‚ àª•àª¾àª® àªªà«‚àª°à«àª£ àª¥àª¯à«àª‚ àª›à«‡. àª†àªªàª¨à«‹ àªªà«àª°àª¤àª¿àª¸àª¾àª¦ àª…àª®àª¾àª°àª¾ àª®àª¾àªŸà«‡ àª®àª¹àª¤à«àªµàª¨à«‹ àª›à«‡. àª†àª­àª¾àª°.",
    end: true
  },

  task_pending: {
    prompt:
      "àª®àª¾àª« àª•àª°àª¶à«‹ àª•à«‡ àª†àªªàª¨à«àª‚ àª•àª¾àª® àª¹àªœà« àªªà«‚àª°à«àª£ àª¥àª¯à«àª‚ àª¨àª¥à«€. àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª†àªªàª¨à«€ àª¸àª®àª¸à«àª¯àª¾àª¨à«€ àªµàª¿àª—àª¤à«‹ àªœàª£àª¾àªµàª¶à«‹."
  },

  problem_recorded: {
    prompt:
      "àª†àª­àª¾àª°. àª†àªªàª¨à«€ àª®àª¾àª¹àª¿àª¤à«€ àª¨à«‹àª‚àª§àª¾àªˆ àª—àªˆ àª›à«‡. àª…àª®àª¾àª°à«€ àªŸà«€àª® àªœàª²àª¦à«€ àªœ àª¸àª‚àªªàª°à«àª• àª•àª°àª¶à«‡.",
    end: true
  },

  end_no_time: {
    prompt:
      "àª¬àª°àª¾àª¬àª°. àª•à«‹àªˆ àª¸àª®àª¸à«àª¯àª¾ àª¨àª¥à«€. àª†àªªàª¨à«‹ àª¸àª®àª¯ àª†àªªàªµàª¾ àª¬àª¦àª² àª†àª­àª¾àª°.",
    end: true
  }
};

/* ======================
   TTS CACHE
====================== */
async function generateAudio(text, file) {
  const filePath = path.join(AUDIO_DIR, file);
  if (fs.existsSync(filePath)) return;

  const [res] = await ttsClient.synthesizeSpeech({
    input: { text },
    voice: { languageCode: "gu-IN" },
    audioConfig: { audioEncoding: "MP3" }
  });

  fs.writeFileSync(filePath, res.audioContent);
}

async function preloadAllAudio() {
  for (const key in FLOW) {
    await generateAudio(FLOW[key].prompt, `${key}.mp3`);
  }
  await generateAudio("àª•à«ƒàªªàª¾ àª•àª°à«€àª¨à«‡ àª«àª°à«€àª¥à«€ àª•àª¹à«‡àª¶à«‹?", "retry.mp3");
}

/* ======================
   LLM INTENT CLASSIFIER
====================== */
async function detectNextState(currentState, userText) {
  const prompt = `
You are a Gujarati phone-call intent classifier.

Current step: ${currentState}

Allowed transitions:
intro â†’ task_check | end_no_time
task_check â†’ task_done | task_pending

User said (Gujarati):
"${userText}"

Reply ONLY with:
task_check, task_done, task_pending, end_no_time, unknown
`;

  const r = await fetch("https://api.groq.com/openai/v1/chat/completions", {
    method: "POST",
    headers: {
      Authorization: `Bearer ${process.env.GROQ_API_KEY}`,
      "Content-Type": "application/json"
    },
    body: JSON.stringify({
      model: "llama-3.1-8b-instant",
      messages: [{ role: "user", content: prompt }],
      temperature: 0
    })
  });

  const j = await r.json();
  return j.choices?.[0]?.message?.content?.trim();
}

/* ======================
   GOOGLE SHEET LOG
====================== */
function logToSheet(session) {
  sheets.spreadsheets.values.append({
    spreadsheetId: SHEET_ID,
    range: "Call_Logs!A:H",
    valueInputOption: "USER_ENTERED",
    requestBody: {
      values: [[
        new Date(session.startTime).toISOString(),
        session.sid,
        session.from,
        session.agentTexts.join(" | "),
        session.userTexts.join(" | "),
        session.result,
        Math.floor((Date.now() - session.startTime) / 1000),
        "Completed"
      ]]
    }
  }).catch(console.error);
}

/* ======================
   OUTBOUND CALL API
====================== */
app.post("/call", async (req, res) => {
  try {
    const { to } = req.body;

    if (!to) return res.status(400).json({ error: "Missing 'to' number" });
    if (!process.env.TWILIO_FROM_NUMBER)
      return res.status(500).json({ error: "TWILIO_FROM_NUMBER not set" });

    const twilioCall = await twilioClient.calls.create({
      to,
      from: process.env.TWILIO_FROM_NUMBER,
      url: `${BASE_URL}/answer`,
      method: "POST",
      statusCallback: `${BASE_URL}/call-status`,
      statusCallbackEvent: ["completed"],
      statusCallbackMethod: "POST"
    });

    res.json({ status: "calling", sid: twilioCall.sid, to });
  } catch (err) {
    console.error("Outbound call error:", err);
    res.status(500).json({ error: err.message });
  }
});

/* ======================
   ANSWER WEBHOOK
====================== */
app.post("/answer", (req, res) => {
  const sid = req.body.CallSid;

  callSessions.set(sid, {
    sid,
    state: "intro",
    startTime: Date.now(),
    agentTexts: [FLOW.intro.prompt],
    userTexts: [],
    from: req.body.From,
    result: ""
  });

  res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/intro.mp3</Play>
  <Gather input="speech" language="gu-IN"
    action="${BASE_URL}/listen"
    method="POST"
    timeout="6"
    speechTimeout="auto"/>
</Response>
`);
});

/* ======================
   LISTEN LOOP (FIXED)
====================== */
app.post("/listen", async (req, res) => {
  const session = callSessions.get(req.body.CallSid);
  if (!session) return res.type("text/xml").send("<Response><Hangup/></Response>");

  const text = (req.body.SpeechResult || "").trim();
  if (!text) {
    return res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/retry.mp3</Play>
  <Gather input="speech" language="gu-IN"
    action="${BASE_URL}/listen"
    method="POST"
    timeout="6"
    speechTimeout="auto"/>
</Response>
`);
  }

  session.userTexts.push(text);

  let nextState;

  // ðŸ”’ HARD STOP LOGIC
  if (session.state === "task_pending") {
    nextState = "problem_recorded";
  } else {
    nextState = await detectNextState(session.state, text);
  }

  if (!FLOW[nextState]) {
    return res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/retry.mp3</Play>
  <Gather input="speech" language="gu-IN"
    action="${BASE_URL}/listen"
    method="POST"
    timeout="6"
    speechTimeout="auto"/>
</Response>
`);
  }

  session.agentTexts.push(FLOW[nextState].prompt);

  if (FLOW[nextState].end) {
    session.result = nextState;
    logToSheet(session);
    callSessions.delete(session.sid);

    return res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/${nextState}.mp3</Play>
  <Hangup/>
</Response>
`);
  }

  session.state = nextState;

  res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/${nextState}.mp3</Play>
  <Gather input="speech" language="gu-IN"
    action="${BASE_URL}/listen"
    method="POST"
    timeout="6"
    speechTimeout="auto"/>
</Response>
`);
});

/* ======================
   CALL STATUS CALLBACK
====================== */
app.post("/call-status", (req, res) => {
  const sid = req.body.CallSid;
  const session = callSessions.get(sid);

  if (session && !session.result) {
    session.result = "abandoned";
    logToSheet(session);
    callSessions.delete(sid);
  }

  res.sendStatus(200);
});

/* ======================
   START SERVER
====================== */
app.listen(PORT, async () => {
  await preloadAllAudio();
  console.log("âœ… Gujarati AI Voice Agent running (Production Ready)");
});
