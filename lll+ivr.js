/*************************************************
 * GUJARATI AI VOICE AGENT â€“ HUMANATIC + ROBUST
 * State-based | Rule-driven | Scriptless
 * SINGLE + BULK CALL ENABLED
 * IVR + LLM HYBRID (SAFE MODE â€“ GROQ)
 *************************************************/

import express from "express";
import bodyParser from "body-parser";
import dotenv from "dotenv";
import fs from "fs";
import path from "path";
import { fileURLToPath } from "url";
import twilio from "twilio";
import textToSpeech from "@google-cloud/text-to-speech";
import { google } from "googleapis";
import fetch from "node-fetch";

import { STATES } from "./conversation/states.js";
import { RESPONSES } from "./conversation/responses.js";
import { RULES } from "./conversation/rules.js";

dotenv.config();

/* ======================
   BASIC SETUP
====================== */
const app = express();
app.use(bodyParser.urlencoded({ extended: false }));
app.use(bodyParser.json());

const PORT = process.env.PORT || 10000;
const BASE_URL = process.env.BASE_URL;

/* ======================
   TWILIO
====================== */
const twilioClient = twilio(
  process.env.TWILIO_ACCOUNT_SID,
  process.env.TWILIO_AUTH_TOKEN
);

/* ======================
   GOOGLE TTS
====================== */
const ttsClient = new textToSpeech.TextToSpeechClient();

/* ======================
   GOOGLE SHEETS
====================== */
const auth = new google.auth.GoogleAuth({
  credentials: JSON.parse(process.env.GOOGLE_SERVICE_ACCOUNT),
  scopes: ["https://www.googleapis.com/auth/spreadsheets"]
});
const sheets = google.sheets({ version: "v4", auth });
const SHEET_ID = process.env.GOOGLE_SHEET_ID;

/* ======================
   FILE SYSTEM
====================== */
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);
const AUDIO_DIR = path.join(__dirname, "audio");

if (!fs.existsSync(AUDIO_DIR)) fs.mkdirSync(AUDIO_DIR);
app.use("/audio", express.static(AUDIO_DIR));

/* ======================
   SESSION MEMORY
====================== */
const sessions = new Map();

/* ======================
   AUDIO CACHE
====================== */
async function generateAudio(text, file) {
  const filePath = path.join(AUDIO_DIR, file);
  if (fs.existsSync(filePath)) return;

  const [res] = await ttsClient.synthesizeSpeech({
    input: { text },
    voice: { languageCode: "gu-IN" },
    audioConfig: { audioEncoding: "MP3" }
  });

  fs.writeFileSync(filePath, res.audioContent);
}

async function preloadAll() {
  for (const key in RESPONSES) {
    await generateAudio(RESPONSES[key].text, `${key}.mp3`);
  }
}

/* ======================
   HELPERS
====================== */
function hasGujarati(text) {
  return /[\u0A80-\u0AFF]/.test(text);
}

function normalizeMixedGujarati(text) {
  const dict = {
    aadhar: "àª†àª§àª¾àª°",
    aadhaar: "àª†àª§àª¾àª°",
    card: "àª•àª¾àª°à«àª¡",
    data: "àª¡à«‡àªŸàª¾",
    entry: "àªàª¨à«àªŸà«àª°à«€",
    update: "àª¸à«àª§àª¾àª°à«‹",
    correction: "àª¸à«àª§àª¾àª°à«‹",
    name: "àª¨àª¾àª®",
    address: "àª¸àª°àª¨àª¾àª®à«àª‚",
    mobile: "àª®à«‹àª¬àª¾àª‡àª²",
    number: "àª¨àª‚àª¬àª°",
    change: "àª«à«‡àª°àª«àª¾àª°"
  };

  let out = text;
  for (const k in dict) {
    out = out.replace(new RegExp(`\\b${k}\\b`, "gi"), dict[k]);
  }
  return out;
}

/* ======================
   IVR INTENT DETECTION
====================== */
function detectTaskStatus(text) {
  const pending = ["àª¨àª¥à«€", "àª¬àª¾àª•à«€", "àª¹àªœà«", "àªªà«‚àª°à«àª£ àª¨àª¥à«€", "àªšàª¾àª²à« àª›à«‡"];
  const done = ["àªªà«‚àª°à«àª£ àª¥àª¯à«àª‚", "àª¥àªˆ àª—àª¯à«àª‚", "àª¥àª¯à«àª‚ àª›à«‡", "àª®àª³à«€ àª—àª¯à«àª‚"];

  const p = pending.some(w => text.includes(w));
  const d = done.some(w => text.includes(w));

  if (p && !d) return { status: "PENDING", confidence: 90 };
  if (d && !p) return { status: "DONE", confidence: 90 };
  if (p && d) return { status: "UNCLEAR", confidence: 40 };
  return { status: "UNCLEAR", confidence: 30 };
}

/* =====================================================
   ðŸ”¥ LLM ASSIST â€” GROQ (SAFE FALLBACK ONLY)
===================================================== */
async function llmAssist(text) {
  try {
    const resp = await fetch(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        method: "POST",
        headers: {
          "Authorization": `Bearer ${process.env.GROQ_API_KEY}`,
          "Content-Type": "application/json"
        },
        body: JSON.stringify({
          model: "llama-3.1-70b-versatile",
          messages: [
            {
              role: "system",
              content:
                "You classify Gujarati speech strictly. Respond ONLY in JSON."
            },
            {
              role: "user",
              content: `
Text:
"${text}"

Return ONLY:
{
  "intent": "DONE | PENDING | BUSY | OTHER",
  "summary": "short Gujarati summary"
}`
            }
          ],
          temperature: 0
        })
      }
    );

    const data = await resp.json();
    return JSON.parse(data.choices[0].message.content);
  } catch {
    return { intent: "OTHER", summary: text };
  }
}

/* ======================
   LISTEN (IVR + LLM)
====================== */
app.post("/listen", async (req, res) => {
  const s = sessions.get(req.body.CallSid);
  const raw = (req.body.SpeechResult || "").trim();

  if (!raw) {
    const next = RULES.nextOnUnclear(++s.unclearCount);
    s.agentTexts.push(RESPONSES[next].text);
    return res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/${next}.mp3</Play>
  <Gather input="speech" language="gu-IN"
    timeout="12" speechTimeout="1"
    action="${BASE_URL}/listen"/>
</Response>
`);
  }

  if (hasGujarati(raw)) s.userBuffer.push(normalizeMixedGujarati(raw));

  let { status, confidence } = detectTaskStatus(raw);
  let next;

  if (confidence < 50) {
    const llm = await llmAssist(raw);
    s.userTexts.push(llm.summary);

    if (llm.intent === "DONE") status = "DONE";
    else if (llm.intent === "PENDING") status = "PENDING";
    else if (llm.intent === "BUSY") next = STATES.CALLBACK_TIME;
  }

  if (!next) {
    next =
      status === "DONE"
        ? STATES.TASK_DONE
        : status === "PENDING"
        ? STATES.TASK_PENDING
        : RULES.nextOnUnclear(++s.unclearCount);
  }

  s.agentTexts.push(RESPONSES[next].text);

  if (RESPONSES[next].end) {
    s.result = next;
    s.endTime = Date.now();
    sessions.delete(s.sid);

    return res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/${next}.mp3</Play>
  <Hangup/>
</Response>
`);
  }

  s.state = next;
  res.type("text/xml").send(`
<Response>
  <Play>${BASE_URL}/audio/${next}.mp3</Play>
  <Gather input="speech" language="gu-IN"
    timeout="12" speechTimeout="1"
    action="${BASE_URL}/listen"/>
</Response>
`);
});

/* ======================
   START
====================== */
app.listen(PORT, async () => {
  await preloadAll();
  console.log("âœ… Gujarati AI Voice Agent â€“ IVR + GROQ LLM READY");
});
